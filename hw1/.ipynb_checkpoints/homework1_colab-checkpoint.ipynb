{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6QA1D6eIszX_"
   },
   "source": [
    "# Homework 1. Making Your First Neural Network: Part 6.\n",
    "# Important notes:\n",
    "1. Do not change the name of the network or change the network constructor to take arguments. This will break the autograder.\n",
    "2. Only changes to areas of the code marked \"**modify me**\" will be graded. You may not change function signatures or return values from these functions or you will fail the tests.\n",
    "# Part 0: Initial setup\n",
    "\n",
    "To enable GPU:\n",
    "1.   Click Edit -> Notebook settings\n",
    "2.   Under Runtime type select Python 3\n",
    "3.   Under Hardware Accelerator select GPU\n",
    "4.   On the right side of this page, click connect to a hosted runtime\n",
    "\n",
    "\n",
    "If you ever see an error about needing third-party cookies enabled, you can disable blocking them or whitelist them.\n",
    "Here is a simple way to whitelist (in Chrome)\n",
    "\n",
    "For Chrome:\n",
    "1.   Go to settings and search \"content settings\"\n",
    "2.   Click the \"content settings\" button\n",
    "3.   Click \"Cookies\"\n",
    "4.   Uncheck \"Block third-party cookies\" or\n",
    "5.   Click Add next to Allow and type https://[*.]googleusercontent.com:443"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DHxEgxT6YwR8"
   },
   "outputs": [],
   "source": [
    "# This shows how to connect your google drive account with a colab instance. It's pretty easy.\n",
    "# Load the Drive helper and mount\n",
    "from google.colab import drive\n",
    "\n",
    "# This will prompt for authorization.\n",
    "drive.mount('/gdrive')\n",
    "# Create a directory and mount Google Drive using that directory.\n",
    "\n",
    "# Now let's test that Google Drive is up and running. \n",
    "# You may have to change \"My Drive\" if you have renamed it something else.\n",
    "!ls \"/gdrive/My Drive\"\n",
    "\n",
    "!echo \"Hello Google Drive\" > \"/gdrive/My Drive/foo.txt\"\n",
    "!cat \"/gdrive/My Drive/foo.txt\"\n",
    "!rm \"/gdrive/My Drive/foo.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Gv3f_-svjwm6"
   },
   "source": [
    "# Drive not connecting after it seemed like it worked before?\n",
    "1. First try restarting the runtime via Runtime -> Restart Runtime\n",
    "2. Then try to run the above again.\n",
    "3. If this still doesn't work, call Reset All Runtimes. This is the nuclear option that will delete all your data not saved on your personal drive account, and will erase everything you installed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oINm7sOOdpaL"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "print('Version', torch.__version__)\n",
    "print('CUDA enabled:', torch.cuda.is_available())\n",
    "  \n",
    "# Running this should then print out:\n",
    "# Version 1.1.0\n",
    "# CUDA enabled: True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lrYXOGpsM6TV"
   },
   "outputs": [],
   "source": [
    "# Define some useful save and restoring functions. \n",
    "# You can thank your TAs for providing this code, \n",
    "# it will probably be useful for you in the future as well.\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "\n",
    "class pt_util(object):\n",
    "    # This does more than the simple Pytorch restore. It checks that the names \n",
    "    # of variables match, and if they don't doesn't throw a fit. It is similar \n",
    "    # to how Caffe acts. This is especially useful if you decide to change your\n",
    "    # network architecture but don't want to retrain from scratch.\n",
    "    @staticmethod\n",
    "    def restore(net, save_file):\n",
    "        net_state_dict = net.state_dict()\n",
    "        restore_state_dict = torch.load(save_file)\n",
    "\n",
    "        restored_var_names = set()\n",
    "\n",
    "        print('Restoring:')\n",
    "        for var_name in restore_state_dict.keys():\n",
    "            if var_name in net_state_dict:\n",
    "                var_size = net_state_dict[var_name].size()\n",
    "                restore_size = restore_state_dict[var_name].size()\n",
    "                if var_size != restore_size:\n",
    "                    print('Shape mismatch for var', var_name, 'expected', var_size, 'got', restore_size)\n",
    "                else:\n",
    "                    if isinstance(net_state_dict[var_name], torch.nn.Parameter):\n",
    "                        # backwards compatibility for serialized parameters\n",
    "                        net_state_dict[var_name] = restore_state_dict[var_name].data\n",
    "                    try:\n",
    "                        net_state_dict[var_name].copy_(restore_state_dict[var_name])\n",
    "                        print(str(var_name) + ' -> \\t' + str(var_size) + ' = ' + str(int(np.prod(var_size) * 4 / 10**6)) + 'MB')\n",
    "                        restored_var_names.add(var_name)\n",
    "                    except:\n",
    "                        print('While copying the parameter named {}, whose dimensions in the model are'\n",
    "                              ' {} and whose dimensions in the checkpoint are {}, ...'.format(\n",
    "                                  var_name, var_size, restore_size))\n",
    "                        raise\n",
    "\n",
    "        ignored_var_names = sorted(list(set(restore_state_dict.keys()) - restored_var_names))\n",
    "        unset_var_names = sorted(list(set(net_state_dict.keys()) - restored_var_names))\n",
    "        print('')\n",
    "        if len(ignored_var_names) == 0:\n",
    "            print('Restored all variables')\n",
    "        else:\n",
    "            print('Did not restore:\\n\\t' + '\\n\\t'.join(ignored_var_names))\n",
    "        if len(unset_var_names) == 0:\n",
    "            print('No new variables')\n",
    "        else:\n",
    "            print('Initialized but did not modify:\\n\\t' + '\\n\\t'.join(unset_var_names))\n",
    "\n",
    "        print('Restored %s' % save_file)\n",
    "        \n",
    "    # Restores the last saved network in a folder using file write time.\n",
    "    @staticmethod\n",
    "    def restore_latest(net, folder):\n",
    "        checkpoints = sorted(glob.glob(folder + '/*.pt'), key=os.path.getmtime)\n",
    "        start_it = 0\n",
    "        if len(checkpoints) > 0:\n",
    "            pt_util.restore(net, checkpoints[-1])\n",
    "            start_it = int(re.findall(r'\\d+', checkpoints[-1])[-1])\n",
    "        return start_it\n",
    "\n",
    "    # Saves the network and optionally deletes old save files. \n",
    "    # If num_to_keep is 0, it won't remove any.\n",
    "    @staticmethod\n",
    "    def save(net, file_name, num_to_keep=1):\n",
    "        folder = os.path.dirname(file_name)\n",
    "        if not os.path.exists(folder):\n",
    "            os.makedirs(folder)\n",
    "        torch.save(net.state_dict(), file_name)\n",
    "        extension = os.path.splitext(file_name)[1]\n",
    "        checkpoints = sorted(glob.glob(folder + '/*' + extension), key=os.path.getmtime)\n",
    "        print('Saved %s\\n' % file_name)\n",
    "        if num_to_keep > 0:\n",
    "            for ff in checkpoints[:-num_to_keep]:\n",
    "                os.remove(ff)\n",
    "                \n",
    "    # Shows some tiled images.\n",
    "    @staticmethod\n",
    "    def show_images(images, titles=None, columns=5, max_rows=5):\n",
    "        images = images[:min(len(images), max_rows * columns)]\n",
    "\n",
    "        plt.figure(figsize=(20, 10))\n",
    "        for ii, image in enumerate(images):\n",
    "            plt.subplot(len(images) / columns + 1, columns, ii + 1)\n",
    "            plt.axis('off')\n",
    "            if titles is not None and ii < len(titles):\n",
    "                plt.title(str(titles[ii]))\n",
    "            plt.imshow(image)\n",
    "        plt.show()\n",
    "\n",
    "    @staticmethod\n",
    "    def to_numpy(array):\n",
    "        if isinstance(array, torch.Tensor):\n",
    "            return array.detach().cpu().numpy()\n",
    "        elif isinstance(array, dict):\n",
    "            return {key: pt_util.to_numpy(val) for key, val in array.items()}\n",
    "        else:\n",
    "            return np.asarray(array)\n",
    "\n",
    "    @staticmethod\n",
    "    def from_numpy(np_array):\n",
    "        if isinstance(np_array, list):\n",
    "            try:\n",
    "                np_array = np.stack(np_array, 0)\n",
    "            except ValueError:\n",
    "                np_array = np.stack([from_numpy(val) for val in np_array], 0)\n",
    "        elif isinstance(np_array, dict):\n",
    "            return {key: from_numpy(val) for key, val in np_array.items()}\n",
    "        np_array = np.asarray(np_array)\n",
    "        if np_array.dtype == np.uint32:\n",
    "            print(\"numpy -> torch dtype uint32 not supported, using int32\")\n",
    "            np_array = np_array.astype(np.int32)\n",
    "        elif np_array.dtype == np.dtype(\"O\"):\n",
    "            print(\"numpy -> torch dtype Object not supported, returning numpy array\")\n",
    "            return np_array\n",
    "        elif np_array.dtype.type == np.str_:\n",
    "            print(\"numpy -> torch dtype numpy.str_ not supported, returning numpy array\")\n",
    "            return np_array\n",
    "        return torch.from_numpy(np_array)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u486U-pUJnDY"
   },
   "source": [
    "# Part 1: Implementing a network for MNIST\n",
    "# 1.1\n",
    "We would like you to implement a simple network for MNIST. \n",
    "\n",
    "MNIST data is 28x28, so the first thing you will need to do is reshape the data to be one long vector.\n",
    "\n",
    "Your basic network layers will go in the `__init__` function, and the forward call will pass the data through.\n",
    "\n",
    "For some sample code, look at https://github.com/pytorch/examples/blob/master/mnist/main.py\n",
    "\n",
    "Additionally, fill in the loss function for the network.\n",
    "\n",
    "# 1.2\n",
    "Call the forward and backward passes (again, see https://github.com/pytorch/examples/blob/master/mnist/main.py) in the train and test functions.\n",
    "\n",
    "# Helpful functions\n",
    "- https://pytorch.org/docs/stable/tensors.html\n",
    "- https://pytorch.org/docs/stable/nn.html\n",
    "- You can call `pt_util.to_numpy(x)` to get a numpy array from a torch tensor x.\n",
    "- `pt_util.from_numpy(x)` makes a torch Tensor from the numpy array x.\n",
    "\n",
    "# Common Oopsies\n",
    "- __Q__ It only runs for one iteration and says it's done: __A__ We provided code that automatically loads the most recent file. If you don't want to start from that checkpoint, simply find it in your google drive and delete it.\n",
    "- __Q__ I want to save more than just the last checkpoint: __A__ You can change the save function to save any number of previous checkpoints. You can also tell it to save all of them (not delete anything), by passing in 0.\n",
    "- __Q__ Pytorch is saying things are the wrong shape: __A__ You can easily reshape things using the `view` function (https://pytorch.org/docs/stable/tensors.html#torch.Tensor.view). It is like the Numpy `reshape` function.\n",
    "- __Q__ Pytorch is saying things are on the wrong device: __A__ You can move data between devices with the `.to(device)` call. Generally, all arguments to a function will need to be on the same device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0oKKR9EsoK9G"
   },
   "outputs": [],
   "source": [
    "# This is where you define your network architecture.\n",
    "# Note: The TAs know this follows the PyTorch MNIST tutorial available at \n",
    "# https://github.com/pytorch/examples/blob/master/mnist/main.py\n",
    "# Where do you think we got it from? \n",
    "# So we are asking you to implement something slightly different. \n",
    "# You can use that as a guide, but make sure you understand what it all does.\n",
    "\n",
    "import tqdm\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "class MNISTNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        # modify me\n",
    "        super(MNISTNet, self).__init__()\n",
    "        # The network should be as follows:\n",
    "        # One fully connected layer with 1024 outputs.\n",
    "        # One fully connected layer with 512 outputs.\n",
    "        # Then the final classification layer.\n",
    "        # All the nonlinearities should be ReLU.\n",
    "        raise NotImplementedError('Define the layers here')\n",
    "\n",
    "    def forward(self, x):\n",
    "        # modify me\n",
    "        raise NotImplementedError('Define the forward pass')\n",
    "      \n",
    "    def save_model(self, file_path, num_to_keep=1):\n",
    "        pt_util.save(self, file_path, num_to_keep)\n",
    "        \n",
    "    # prediction and label should be PyTorch Tensors.\n",
    "    # You should return the result from the Cross Entropy function.\n",
    "    # You should also use the cross_entropy loss rather than the NLL loss.\n",
    "    def loss(self, prediction, label, reduction='mean'):\n",
    "        # modify me\n",
    "        raise NotImplementedError('Define the loss here')\n",
    "\n",
    "    def load_model(self, file_path):\n",
    "        pt_util.restore(self, file_path)\n",
    "\n",
    "    def load_last_model(self, dir_path):\n",
    "        return pt_util.restore_latest(self, dir_path)\n",
    "\n",
    "def train_step(model, data, label, optimizer):\n",
    "    # modify me\n",
    "    raise NotImplementedError('Call the forward pass, loss, and backward here.')\n",
    "    return loss\n",
    "\n",
    "def train(model, device, train_loader, optimizer, epoch, log_interval):\n",
    "    model.train()\n",
    "    for batch_idx, (data, label) in enumerate(tqdm.tqdm(train_loader)):\n",
    "        data, label = data.to(device), label.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        loss = train_step(model, data, label, optimizer)        \n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "\n",
    "def test_step(model, data, label):\n",
    "    # modify me\n",
    "    raise NotImplementedError('Call the forward pass, loss, and get the predictions from the network. No need to call backward. The test loss will be averaged over the whole epoch, so do not average it here.')\n",
    "    return test_loss, pred\n",
    "\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    correct_images = []\n",
    "    correct_values = []\n",
    "\n",
    "    error_images = []\n",
    "    predicted_values = []\n",
    "    gt_values = []\n",
    "    with torch.no_grad():\n",
    "        for data, label in tqdm.tqdm(test_loader):\n",
    "            data, label = data.to(device), label.to(device)\n",
    "            test_loss_on, pred = test_step(model, data, label)\n",
    "            test_loss += test_loss_on            \n",
    "            correct_mask = pred.eq(label.view_as(pred))\n",
    "            num_correct = correct_mask.sum().item()\n",
    "            correct += num_correct\n",
    "            if num_correct > 0:\n",
    "                correct_images.append(pt_util.to_numpy(data[correct_mask, ...]))\n",
    "                correct_value_data = pt_util.to_numpy(label[correct_mask])\n",
    "                correct_values.append(correct_value_data)\n",
    "            if num_correct < len(label):\n",
    "                error_data = pt_util.to_numpy(data[~correct_mask, ...])\n",
    "                error_images.append(error_data)\n",
    "                predicted_value_data = pt_util.to_numpy(pred[~correct_mask])\n",
    "                predicted_values.append(predicted_value_data)\n",
    "                gt_value_data = pt_util.to_numpy(label[~correct_mask])\n",
    "                gt_values.append(gt_value_data)\n",
    "    correct_images = np.concatenate(correct_images, axis=0)[:, 0, :, :]\n",
    "    error_images = np.concatenate(error_images, axis=0)[:, 0, :, :]\n",
    "    predicted_values = np.concatenate(predicted_values, axis=0)\n",
    "    correct_values = np.concatenate(correct_values, axis=0)\n",
    "    gt_values = np.concatenate(gt_values, axis=0)\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_accuracy = 100. * correct / len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "    return test_loss, test_accuracy, correct_images, correct_values, error_images, predicted_values, gt_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pNf3AoHVvKXI"
   },
   "outputs": [],
   "source": [
    "# Play around with these constants, you may find a better setting.\n",
    "def get_constants():\n",
    "    # modify me (if you want)\n",
    "    BATCH_SIZE = 256\n",
    "    TEST_BATCH_SIZE = 1000\n",
    "    EPOCHS = 10\n",
    "    LEARNING_RATE = 0.01\n",
    "    MOMENTUM = 0.9\n",
    "\n",
    "    return {'BATCH_SIZE': BATCH_SIZE,\n",
    "            'TEST_BATCH_SIZE': TEST_BATCH_SIZE,\n",
    "            'EPOCHS': EPOCHS,\n",
    "            'LEARNING_RATE': LEARNING_RATE,\n",
    "            'MOMENTUM': MOMENTUM,\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "50zDbqjXu_Qq"
   },
   "outputs": [],
   "source": [
    "# Now the actual training code\n",
    "import multiprocessing\n",
    "import traceback\n",
    "\n",
    "def main():\n",
    "    constants = get_constants()\n",
    "    BATCH_SIZE = constants['BATCH_SIZE']\n",
    "    TEST_BATCH_SIZE = constants['TEST_BATCH_SIZE']\n",
    "    EPOCHS = constants['EPOCHS']\n",
    "    LEARNING_RATE = constants['LEARNING_RATE']\n",
    "    MOMENTUM = constants['MOMENTUM']\n",
    "\n",
    "    SEED = 0\n",
    "    LOG_INTERVAL = 100\n",
    "    USE_CUDA = True\n",
    "\n",
    "    use_cuda = USE_CUDA and torch.cuda.is_available()\n",
    "\n",
    "    torch.manual_seed(SEED)\n",
    "\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "    print('Using device', device)\n",
    "    print('num cpus:', multiprocessing.cpu_count())\n",
    "\n",
    "    kwargs = {'num_workers': multiprocessing.cpu_count(),\n",
    "            'pin_memory': True} if use_cuda else {}\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST('../data', train=True, download=True,\n",
    "                    transform=transforms.Compose([\n",
    "                        transforms.ToTensor(),\n",
    "                        transforms.Normalize((0.1307,), (0.3081,))\n",
    "                    ])),\n",
    "        batch_size=BATCH_SIZE, shuffle=True, **kwargs)\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
    "                        transforms.ToTensor(),\n",
    "                        transforms.Normalize((0.1307,), (0.3081,))\n",
    "                    ])),\n",
    "        batch_size=TEST_BATCH_SIZE, **kwargs)\n",
    "\n",
    "\n",
    "    model = MNISTNet().to(device)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=MOMENTUM)\n",
    "    # This will save checkpoints in your Google Drive account.\n",
    "    start_epoch = model.load_last_model('/gdrive/My Drive/colab_files/homework1/mnist/checkpoints')\n",
    "    test_loss, test_accuracy, correct_images, correct_val, error_images, predicted_val, gt_val = test(model, device, test_loader)\n",
    "    pt_util.show_images(correct_images, ['correct: %s' % aa for aa in correct_val])\n",
    "    pt_util.show_images(error_images, ['pred: %s, actual: %s' % (aa, bb) for aa, bb in zip(predicted_val, gt_val)])\n",
    "    try:\n",
    "        for epoch in range(start_epoch, EPOCHS + 1):\n",
    "            train(model, device, train_loader, optimizer, epoch, LOG_INTERVAL)\n",
    "            test(model, device, test_loader)\n",
    "            model.save_model('/gdrive/My Drive/colab_files/homework1/mnist/checkpoints/%03d.pt' % epoch)\n",
    "    except KeyboardInterrupt as ke:\n",
    "        print('Interrupted')\n",
    "    except:\n",
    "        traceback.print_exc()\n",
    "    finally:\n",
    "        model.save_model('/gdrive/My Drive/colab_files/homework1/mnist/checkpoints/%03d.pt' % epoch)\n",
    "        pt_util.show_images(correct_images, ['correct: %s' % aa for aa in correct_val])\n",
    "        pt_util.show_images(error_images, ['pred: %s, actual: %s' % (aa, bb) for aa, bb in zip(predicted_val, gt_val)])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MvJx-sBwOHV5"
   },
   "outputs": [],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kwAXWXg8jzS4"
   },
   "source": [
    "# Download a copy for submission and put it in your repository.\n",
    "File -> download .ipynb"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "homework1_colab.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
